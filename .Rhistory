rpart.plot(fit.CART)
fit.CART <- rpart(LABEL ~ . , data = cbind(as.data.frame(as.matrix(train_doc)), LABEL = factor(training_labels)),
method = "class", cp = 2e-3)
rpart.plot(fit.CART)
fit.CART <- rpart(LABEL ~ . , data = cbind(as.data.frame(as.matrix(train_doc)), LABEL = factor(training_labels)),
method = "class", cp = 2e-2)
rpart.plot(fit.CART)
fit.CART <- rpart(LABEL ~ . , data = cbind(as.data.frame(as.matrix(train_doc)), LABEL = factor(training_labels)),
method = "class", cp = 2e-1)
rpart.plot(fit.CART)
fit.CART <- rpart(LABEL ~ . , data = cbind(as.data.frame(as.matrix(train_doc)), LABEL = factor(training_labels)),
method = "class", cp = 1e-5)
rpart.plot(fit.CART)
fit.CART <- rpart(LABEL ~ . , data = cbind(as.data.frame(as.matrix(train_doc)), LABEL = factor(training_labels)),
method = "class", cp = 1e-10)
rpart.plot(fit.CART)
fit.CART <- rpart(LABEL ~ . , data = cbind(as.data.frame(as.matrix(train_doc)), LABEL = factor(training_labels)),
method = "class", cp = 1e-3)
rpart.plot(fit.CART)
fit.CART <- rpart(LABEL ~ . , data = cbind(as.data.frame(as.matrix(train_doc)), LABEL = factor(training_labels)),
method = "class", cp = 1e-3, minsplit = 5)
rpart.plot(fit.CART)
fit.CART <- rpart(LABEL ~ . , data = cbind(as.data.frame(as.matrix(train_doc)), LABEL = factor(training_labels)),
method = "class", cp = 1e-2, minsplit = 10)
rpart.plot(fit.CART)
fit.CART <- rpart(LABEL ~ . , data = cbind(as.data.frame(as.matrix(train_doc)), LABEL = factor(training_labels)),
method = "class", cp = 1e-2, minsplit = 15)
rpart.plot(fit.CART)
fit.CART <- rpart(LABEL ~ . , data = cbind(as.data.frame(as.matrix(train_doc)), LABEL = factor(training_labels)),
method = "class", minsplit = 10)
rpart.plot(fit.CART)
preds <- predict(fit.CART, type = "class")
classification_report(training_labels, preds)
# in testing set
preds <- predict(fit.CART, newdata = as.data.frame(as.matrix(test_doc)), type = "class")
classification_report(testing_labels, preds)
fit.CART <- rpart(LABEL ~ . , data = cbind(as.data.frame(as.matrix(train_doc)), LABEL = factor(training_labels)),
method = "class", minsplit = 4)
rpart.plot(fit.CART)
# in training set
preds <- predict(fit.CART, type = "class")
classification_report(training_labels, preds)
rm(fit.CART)
library(randomForest)
fit.rf <- randomForest(x = as.matrix(train_doc), y = factor(training_labels))
summary(fit.rf)
fit.rf
fit.rf$importance
varImpPlot(fit.rf)
varImpPlot(fit.rf, type = 2)
?varImpPlot
varImpPlot(fit.rf, n.var = 10)
varImpPlot(fit.rf, n.var = 10, type = 1)
varImpPlot(fit.rf, n.var = 10, type = 3)
varImpPlot(fit.rf, n.var = 10)
varImpPlot(fit.rf, n.var = 15)
varImpPlot(fit.rf, n.var = 25)
varImpPlot(fit.rf, n.var = 10)
varImpPlot(fit.rf, n.var = 15)
# accuracy in training set
preds <- predict(fit.rf)
classification_report(training_labels, preds)
# in testing set
preds <- predict(fit.rf, newdata = as.matrix(test_doc))
classification_report(testing_labels, preds)
rm(fit.rf)
?tm
rm(list = ls())
# this is just for convenience
load('../datasets/US_president_ML_parts/train_test.Rdata')
install.packages("lsa")
head(traindata)
train_doc <- traindata %>% cast_sparse(date, word, n)
dim(train_doc)
?lsa
library(lsa)
a <- lsa(train_doc, dims = 20)
object.size(a)
?object.size
object.size(a, units = "Mb")
format(object.size(a), units = "MB")
a$tk
dim(a$tk)
a$sk
dim(train_doc)
?`svd,Matrix-method``
`
?`svd,Matrix-method`
?svd
rm(a)
lsa.fit <- svd(train_doc, nu = 25, nv = 25)
lsa.fit$d
dim(lsa.fit$u)
?svd
dim(lsa.fit$v)
rownames(lsa.fit$v)
rownames(lsa.fit$v) <- colnames(train_doc)
head(lsa.fit$v, 2)
?sort
tmp <- sort(abs(lsa.fit$v[, 1]), index.return = T)
head(tmp$x)
tmp <- rownames(sort(abs(lsa.fit$v[, 1]), decreasing = T)[1:10])
tmp
sort(abs(lsa.fit$v[, 1]), decreasing = T)[1:10]
names(sort(abs(lsa.fit$v[, 1]), decreasing = T)[1:10])
# create a blank matrix to store all topics
topic_mat <- matrix(NA, nrow = 25, ncol = 10)
rownames(topic_mat) <- paste("Topic", 1:25)
colnames(topic_mat) <- paste("Word", 1:10)
topic_mat <- apply(abs(lsa.fit$v), 2, names(sort(x, decreasing = T)[1:10]) )
topic_mat <- apply(abs(lsa.fit$v), 2, function(x) {names(sort(x, decreasing = T)[1:10])} )
View(topic_mat)
# just a simple for loop, using with apply
topic_mat <- apply(abs(lsa.fit$v), 2, function(x) {names(sort(x, decreasing = T)[1:10])} )
topic_mat <- t(topic_mat)  # transpose it so that row-wise we have topics, and columns are the words
rownames(topic_mat) <- paste("Topic", 1:25)
colnames(topic_mat) <- paste("Word", 1:10)
View(topic_mat)
dim(lsa.fit$u)
topic_mat
knitr::knit_print(topic_mat)
vignette('knit_print', package = 'knitr')
knitr::asis_output(topic_mat)
as.data.frame(topic_mat)
dim(train_doc)
dim(lsa.fit$v)
new_traindoc <- (1/diag(lsa.fit$d[1:25])) %*% t(lsa.fit$v) %*% t(train_doc)
dim(new_traindoc)
new_traindoc <- train_doc %*% lsa.fit$v %*% (1/diag(lsa.fit$d[1:25]))
dim(new_traindoc)
test_doc <- testdata %>% cast_sparse()
test_doc <- testdata %>% cast_sparse(date, word, n)
dim(test_doc)
dim(train_doc)
testdata <- testdata %>% filter(word %in% colnames(train_doc))
testdata <- testdata %>% filter(word %in% colnames(train_doc)) %>%
rbind( tibble(word = colnames(train_doc), date = NA, n = 0, tf = 0, idf = 0, tf_idf = 0, president = NA, party = NA) )
test_doc <- testdata %>% cast_sparse(date, word, n)
dim(test_doc)
# we add a dummy document containing all the words from training set
testdata <- testdata %>% filter(word %in% colnames(train_doc)) %>%
rbind( tibble(word = colnames(train_doc), date = NA, n = 0, tf = 0, idf = 0, tf_idf = 0, president = NA, party = NA) )
test_doc <- testdata %>% cast_sparse(date, word, n)
test_doc <- test_doc[-nrow(test_doc), ]   # the last document is dummy one
dim(test_doc)
new_testdoc <- test_doc %*% lsa.fit$v %*% (1/diag(lsa.fit$d[1:25]))
dim(new_testdoc)
rownames(new_testdoc)
colnames(new_traindoc)
# finally add some column names
colnames(new_traindoc) <- colnames(new_testdoc) <- paste("Topic", 1:25)
training_labels <- party_names[rownames(train_doc)]
testing_labels <- party_names[rownames(test_doc)]
fit.LDA <- MASS::lda(train_doc, factor(training_labels))
fit.LDA <- MASS::lda(new_traindoc, factor(training_labels))
sum(new_traindoc)
which.na(new_traindoc)
which(is.na(new_traindoc))
new_traindoc[1:10, 1:10]
new_traindoc <- train_doc %*% lsa.fit$v %*% (1/diag(lsa.fit$d[1:25]))
new_traindoc[1:10, 1:10]
new_traindoc <- train_doc %*% lsa.fit$v # %*% (1/diag(lsa.fit$d[1:25]))
new_traindoc[1:10, 1:10]
dim(new_traindoc)
new_traindoc <- train_doc %*% lsa.fit$v %*% (diag(1 / lsa.fit$d[1:25]))
# we add a dummy document containing all the words from training set
testdata <- testdata %>% filter(word %in% colnames(train_doc)) %>%
rbind( tibble(word = colnames(train_doc), date = NA, n = 0, tf = 0, idf = 0, tf_idf = 0, president = NA, party = NA) )
test_doc <- testdata %>% cast_sparse(date, word, n)
test_doc <- test_doc[-nrow(test_doc), ]   # the last document is dummy one
new_testdoc <- test_doc %*% lsa.fit$v %*% (diag(1 / lsa.fit$d[1:25]))
# finally add some column names
colnames(new_traindoc) <- colnames(new_testdoc) <- paste("Topic", 1:25)
new_traindoc[1:5, 1:5]
sum(new_traindoc)
fit.LDA <- MASS::lda(new_traindoc, factor(training_labels))
# in training set
preds <- predict(fit.LDA, newdata = new_traindoc)
classification_report(training_labels, preds$class)
classification_report <- function(True_labels, Predicted_labels){
# Making a function for the classification characteristics for a problem with levels 1 and 0.
# Here x and y are two vectors. x is the actual value while y is the vector of predicted values.
class_table = table(Predicted_labels , True_labels)
cat("Classification Matrix is (Row = Predicted, Column = Actual):\n\n")
print(class_table)
TP <- class_table[1, 1]; FP <- class_table[1, 2]; FN <- class_table[2, 1]; TN <- class_table[2, 2];
Accuracy = (TP+TN)/sum(class_table)
cat("\n Accuracy : ", Accuracy, "\n")
cat("Classification error : ", 1 - Accuracy, "\n\n")
preci = c(TP / (TP + FP), TN / (TN+FN) )
recall = c( TP / (TP + FN), TN / (TN + FP) )
F1 = 2 *(preci*recall)/(preci+recall)
class_df <- data.frame(Class = rownames(class_table), Precision = preci, Recall = recall, F1.measure = F1)
cat("Classification Report :\n")
print(class_df)
Pe = (TP+FP)*(TP+FN)/(sum(class_table)^2) + (TN+FP)*(TN+FN)/(sum(class_table)^2)
cat("\n Cohen's Kappa: ", (Accuracy - Pe)/(1 - Pe) )
}
fit.LDA <- MASS::lda(new_traindoc, factor(training_labels))
# in training set
preds <- predict(fit.LDA, newdata = new_traindoc)
classification_report(training_labels, preds$class)
# in testing set
preds <- predict(fit.LDA, newdata = new_testdoc)
classification_report(testing_labels, preds$class)
sum(test_doc)
sum(new_testdoc)
new_testdoc[1:10, 1:10]
# in training set
preds <- predict(fit.LDA, newdata = new_traindoc)
classification_report(training_labels, preds$class)
# in testing set
preds <- predict(fit.LDA, newdata = new_testdoc)
classification_report(testing_labels, preds$class)
fit.QDA <- MASS::qda(new_traindoc, factor(training_labels))
# in training set
preds <- predict(fit.LDA, newdata = new_traindoc)
classification_report(training_labels, preds$class)
# in testing set
preds <- predict(fit.LDA, newdata = new_testdoc)
classification_report(testing_labels, preds$class)
fit.NB <- naiveBayes(x = as.matrix(new_traindoc), y = factor(training_labels))
# in training set
preds <- predict(fit.NB, newdata = as.matrix(new_traindoc))
classification_report(training_labels, preds)
# in testing set
preds <- predict(fit.NB, newdata = as.matrix(new_testdoc))
classification_report(testing_labels, preds)
new_testdoc <- test_doc %*% lsa.fit$v %*% (diag(1 / lsa.fit$d[1:25]))
# finally add some column names
colnames(new_traindoc) <- colnames(new_testdoc) <- paste("Topic", 1:25)
fit.SVM.poly <- svm(x = as.matrix(new_traindoc), y = factor(training_labels), kernel = "polynomial", cost = 3)
# in training set
preds <- predict(fit.SVM.poly, newdata = as.matrix(new_traindoc))
classification_report(training_labels, preds)
# in testing set
preds <- predict(fit.SVM.poly, newdata = as.matrix(new_testdoc))
classification_report(testing_labels, preds)
fit.SVM.radial <- svm(x = as.matrix(new_traindoc), y = factor(training_labels), kernel = "radial", cost = 2)
# in training set
preds <- predict(fit.SVM.radial, newdata = as.matrix(new_traindoc))
classification_report(training_labels, preds)
# in testing set
preds <- predict(fit.SVM.radial, newdata = as.matrix(new_testdoc))
classification_report(testing_labels, preds)
fit.SVM.poly <- svm(x = as.matrix(new_traindoc), y = factor(training_labels), kernel = "polynomial", cost = 1)
# in training set
preds <- predict(fit.SVM.poly, newdata = as.matrix(new_traindoc))
classification_report(training_labels, preds)
# in testing set
preds <- predict(fit.SVM.poly, newdata = as.matrix(new_testdoc))
classification_report(testing_labels, preds)
fit.SVM.poly <- svm(x = as.matrix(new_traindoc), y = factor(training_labels), kernel = "polynomial", cost = 2)
classification_report(testing_labels, preds)
fit.SVM.poly <- svm(x = as.matrix(new_traindoc), y = factor(training_labels), kernel = "polynomial", cost = 5)
classification_report(testing_labels, preds)
fit.SVM.poly <- svm(x = as.matrix(new_traindoc), y = factor(training_labels), kernel = "polynomial", degree = 5)
# in testing set
preds <- predict(fit.SVM.poly, newdata = as.matrix(new_testdoc))
classification_report(testing_labels, preds)
fit.SVM.poly <- svm(x = as.matrix(new_traindoc), y = factor(training_labels), kernel = "polynomial", degree = 20)
# in testing set
preds <- predict(fit.SVM.poly, newdata = as.matrix(new_testdoc))
classification_report(testing_labels, preds)
fit.SVM.sigmoid <- svm(x = as.matrix(new_traindoc), y = factor(training_labels), kernel = "sigmoid")
# in training set
preds <- predict(fit.SVM.sigmoid, newdata = as.matrix(new_traindoc))
classification_report(training_labels, preds)
# in testing set
preds <- predict(fit.SVM.sigmoid, newdata = as.matrix(new_testdoc))
classification_report(testing_labels, preds)
fit.CART <- rpart(LABEL ~ . , data = cbind(as.data.frame(as.matrix(new_traindoc)), LABEL = factor(training_labels)),
method = "class", minsplit = 10)
rpart.plot(fit.CART)
# in testing set
preds <- predict(fit.CART, newdata = as.data.frame(as.matrix(new_testdoc)), type = "class")
classification_report(testing_labels, preds)
fit.rf <- randomForest(x = as.matrix(new_traindoc), y = factor(training_labels))
# in testing set
preds <- predict(fit.rf, newdata = as.matrix(new_testdoc))
classification_report(testing_labels, preds)
fit.CART <- rpart(LABEL ~ . , data = cbind(as.data.frame(as.matrix(new_traindoc)), LABEL = factor(training_labels)),
method = "class", minsplit = 20)
rpart.plot(fit.CART)
fit.CART <- rpart(LABEL ~ . , data = cbind(as.data.frame(as.matrix(new_traindoc)), LABEL = factor(training_labels)),
method = "class", minsplit = 30)
rpart.plot(fit.CART)
fit.CART <- rpart(LABEL ~ . , data = cbind(as.data.frame(as.matrix(new_traindoc)), LABEL = factor(training_labels)),
method = "class", minsplit = 50)
rpart.plot(fit.CART)
# this is just for convenience
load('../datasets/US_president_ML_parts/train_test.Rdata')
setwd("D:/Dataprojects/Natural_Language_Processing_Soumendu_da/Reports")
library(stringr)
library(tidytext)
library(readr)
library(dplyr)
library(ggplot2)
# this is just for convenience
load('../datasets/US_president_ML_parts/train_test.Rdata')
train_doc <- traindata %>% cast_dtm(date, word, n)
train_doc$dimnames
train_doc
library(topicmodels)
# demo
# set a seed so that the output of the model is predictable
ap_lda <- LDA(AssociatedPress, k = 2, control = list(seed = 1234))
data("AssociatedPress")
# demo
# set a seed so that the output of the model is predictable
ap_lda <- LDA(AssociatedPress, k = 2, control = list(seed = 1234))
ap_lda
rm(ap_lda)
?`LDAcontrol-class`
# demo
# set a seed so that the output of the model is predictable
ap_lda <- LDA(AssociatedPress, k = 2, control = list(seed = 1234, verbose = 1))
# demo
# set a seed so that the output of the model is predictable
ap_lda <- LDA(AssociatedPress, k = 2, control = list(seed = 1234, verbose = 2))
rm(ap_lda)
n_topic = 1
n_topic = 10
train_doc <- traindata %>% cast_dtm(date, word, n)
# set a seed so that the output of the model is predictable
mod.lda <- LDA(train_doc, k = n_topic, control = list(seed = 1234, verbose = 1))
rm(AssociatedPress)
saveRDS(mod.lda, '../datasets/US_president_ML_parts/LDA_traindoc.Rds')
train_topics <- tidy(mod.lda, matrix = "beta")
train_topics <- train_topics %>% group_by(topic) %>% top_n(10, beta) %>% ungroup() %>% arrange(topic, -beta)
train_topics %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(term, beta, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
coord_flip() +
scale_x_reordered()
mod.lda
a <- posterior(mod.lda)
a$topics
dim(a$topics)
rm(a)
new_traindoc <- posterior(mod.lda)$topics
# we add a dummy document containing all the words from training set
testdata <- testdata %>% filter(word %in% colnames(train_doc)) %>%
rbind( tibble(word = colnames(train_doc), date = NA, n = 0, tf = 0, idf = 0, tf_idf = 0, president = NA, party = NA) )
test_doc <- testdata %>% cast_sparse(date, word, n)
test_doc <- test_doc[-nrow(test_doc), ]   # the last document is dummy one
test_doc <- testdata %>% cast_dtm(date, word, n)
test_doc <- test_doc[-nrow(test_doc), ]   # the last document is dummy one
dim(test_doc)
new_testdoc <- posterior(mod.lda, newdata = test_doc)$topics
# finally add some column names
colnames(new_traindoc) <- colnames(new_testdoc) <- paste("Topic", 1:n_topic)
training_labels <- party_names[rownames(train_doc)]
testing_labels <- party_names[rownames(test_doc)]
fit.LDA <- MASS::lda(new_traindoc, factor(training_labels))
# in training set
preds <- predict(fit.LDA, newdata = new_traindoc)
classification_report(training_labels, preds$class)
classification_report <- function(True_labels, Predicted_labels){
# Making a function for the classification characteristics for a problem with levels 1 and 0.
# Here x and y are two vectors. x is the actual value while y is the vector of predicted values.
class_table = table(Predicted_labels , True_labels)
cat("Classification Matrix is (Row = Predicted, Column = Actual):\n\n")
print(class_table)
TP <- class_table[1, 1]; FP <- class_table[1, 2]; FN <- class_table[2, 1]; TN <- class_table[2, 2];
Accuracy = (TP+TN)/sum(class_table)
cat("\n Accuracy : ", Accuracy, "\n")
cat("Classification error : ", 1 - Accuracy, "\n\n")
preci = c(TP / (TP + FP), TN / (TN+FN) )
recall = c( TP / (TP + FN), TN / (TN + FP) )
F1 = 2 *(preci*recall)/(preci+recall)
class_df <- data.frame(Class = rownames(class_table), Precision = preci, Recall = recall, F1.measure = F1)
cat("Classification Report :\n")
print(class_df)
Pe = (TP+FP)*(TP+FN)/(sum(class_table)^2) + (TN+FP)*(TN+FN)/(sum(class_table)^2)
cat("\n Cohen's Kappa: ", (Accuracy - Pe)/(1 - Pe) )
}
fit.LDA <- MASS::lda(new_traindoc, factor(training_labels))
# in training set
preds <- predict(fit.LDA, newdata = new_traindoc)
classification_report(training_labels, preds$class)
# in testing set
preds <- predict(fit.LDA, newdata = new_testdoc)
classification_report(testing_labels, preds$class)
rm(fit.LDA)
library(e1071)
fit.NB <- naiveBayes(x = as.matrix(new_traindoc), y = factor(training_labels))
# in training set
preds <- predict(fit.NB, newdata = as.matrix(new_traindoc))
classification_report(training_labels, preds)
# in testing set
preds <- predict(fit.NB, newdata = as.matrix(new_testdoc))
classification_report(testing_labels, preds)
fit.SVM.poly <- svm(x = as.matrix(new_traindoc), y = factor(training_labels), kernel = "polynomial", degree = 1)
# in training set
preds <- predict(fit.SVM.poly, newdata = as.matrix(new_traindoc))
classification_report(training_labels, preds)
rm(fit.NB)
fit.SVM.poly <- svm(x = as.matrix(new_traindoc), y = factor(training_labels), kernel = "polynomial", degree = 2)
# in training set
preds <- predict(fit.SVM.poly, newdata = as.matrix(new_traindoc))
classification_report(training_labels, preds)
fit.SVM.poly <- svm(x = as.matrix(new_traindoc), y = factor(training_labels), kernel = "polynomial", degree = 3)
# in training set
preds <- predict(fit.SVM.poly, newdata = as.matrix(new_traindoc))
classification_report(training_labels, preds)
fit.SVM.poly <- svm(x = as.matrix(new_traindoc), y = factor(training_labels), kernel = "polynomial", degree = 2)
# in training set
preds <- predict(fit.SVM.poly, newdata = as.matrix(new_traindoc))
classification_report(training_labels, preds)
# in testing set
preds <- predict(fit.SVM.poly, newdata = as.matrix(new_testdoc))
classification_report(testing_labels, preds)
fit.SVM.radial <- svm(x = as.matrix(new_traindoc), y = factor(training_labels), kernel = "radial", cost = 2)
# in training set
preds <- predict(fit.SVM.radial, newdata = as.matrix(new_traindoc))
classification_report(training_labels, preds)
# in testing set
preds <- predict(fit.SVM.radial, newdata = as.matrix(new_testdoc))
classification_report(testing_labels, preds)
fit.SVM.radial <- svm(x = as.matrix(new_traindoc), y = factor(training_labels), kernel = "radial", cost = 3)
# in training set
preds <- predict(fit.SVM.radial, newdata = as.matrix(new_traindoc))
classification_report(training_labels, preds)
# in testing set
preds <- predict(fit.SVM.radial, newdata = as.matrix(new_testdoc))
classification_report(testing_labels, preds)
fit.SVM.radial <- svm(x = as.matrix(new_traindoc), y = factor(training_labels), kernel = "radial", cost = 4)
# in training set
preds <- predict(fit.SVM.radial, newdata = as.matrix(new_traindoc))
classification_report(training_labels, preds)
# in testing set
preds <- predict(fit.SVM.radial, newdata = as.matrix(new_testdoc))
classification_report(testing_labels, preds)
fit.SVM.radial <- svm(x = as.matrix(new_traindoc), y = factor(training_labels), kernel = "radial", cost = 5)
# in training set
preds <- predict(fit.SVM.radial, newdata = as.matrix(new_traindoc))
classification_report(training_labels, preds)
# in testing set
preds <- predict(fit.SVM.radial, newdata = as.matrix(new_testdoc))
classification_report(testing_labels, preds)
fit.SVM.sigmoid <- svm(x = as.matrix(new_traindoc), y = factor(training_labels), kernel = "sigmoid", cost = 1)
# in training set
preds <- predict(fit.SVM.sigmoid, newdata = as.matrix(new_traindoc))
classification_report(training_labels, preds)
# in testing set
preds <- predict(fit.SVM.sigmoid, newdata = as.matrix(new_testdoc))
classification_report(testing_labels, preds)
fit.SVM.sigmoid <- svm(x = as.matrix(new_traindoc), y = factor(training_labels), kernel = "sigmoid", cost = 2)
# in training set
preds <- predict(fit.SVM.sigmoid, newdata = as.matrix(new_traindoc))
classification_report(training_labels, preds)
# in testing set
preds <- predict(fit.SVM.sigmoid, newdata = as.matrix(new_testdoc))
classification_report(testing_labels, preds)
fit.SVM.sigmoid <- svm(x = as.matrix(new_traindoc), y = factor(training_labels), kernel = "sigmoid", cost = 3)
# in training set
preds <- predict(fit.SVM.sigmoid, newdata = as.matrix(new_traindoc))
classification_report(training_labels, preds)
# in testing set
preds <- predict(fit.SVM.sigmoid, newdata = as.matrix(new_testdoc))
classification_report(testing_labels, preds)
rm(fit.SVM.poly)
rm(fit.SVM.radial)
rm(fit.SVM.sigmoid)
library(rpart)
library(rpart.plot)
fit.CART <- rpart(LABEL ~ . , data = cbind(as.data.frame(as.matrix(new_traindoc)), LABEL = factor(training_labels)),
method = "class", minsplit = 50)
rpart.plot(fit.CART)
?rpart.plot
fit.CART <- rpart(LABEL ~ . , data = cbind(as.data.frame(as.matrix(new_traindoc)), LABEL = factor(training_labels)),
method = "class", minsplit = 100)
rpart.plot(fit.CART)
# in training set
preds <- predict(fit.CART, type = "class")
classification_report(training_labels, preds)
# in testing set
preds <- predict(fit.CART, newdata = as.data.frame(as.matrix(new_testdoc)), type = "class")
classification_report(testing_labels, preds)
fit.CART <- rpart(LABEL ~ . , data = cbind(as.data.frame(as.matrix(new_traindoc)), LABEL = factor(training_labels)),
method = "class", minsplit = 50)
rpart.plot(fit.CART)
# in training set
preds <- predict(fit.CART, type = "class")
classification_report(training_labels, preds)
# in testing set
preds <- predict(fit.CART, newdata = as.data.frame(as.matrix(new_testdoc)), type = "class")
classification_report(testing_labels, preds)
fit.CART <- rpart(LABEL ~ . , data = cbind(as.data.frame(as.matrix(new_traindoc)), LABEL = factor(training_labels)),
method = "class", minsplit = 100)
rpart.plot(fit.CART)
# in training set
preds <- predict(fit.CART, type = "class")
classification_report(training_labels, preds)
# in testing set
preds <- predict(fit.CART, newdata = as.data.frame(as.matrix(new_testdoc)), type = "class")
classification_report(testing_labels, preds)
library(randomForest)
fit.rf <- randomForest(x = as.matrix(new_traindoc), y = factor(training_labels))
varImpPlot(fit.rf, n.var = 15)
varImpPlot(fit.rf, n.var = 10)
# accuracy in training set
preds <- predict(fit.rf)
classification_report(training_labels, preds)
# in testing set
preds <- predict(fit.rf, newdata = as.matrix(new_testdoc))
classification_report(testing_labels, preds)
rm(list = ls())
setwd("D:/Dataprojects/Natural_Language_Processing_Soumendu_da/Reports")

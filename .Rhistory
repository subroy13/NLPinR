speech_df
speech_df <- speech_df %>% mutate(text = str_to_lower(text) )
# the next thing is processing apostrophe
patterns <- c(
"n't" = " not",
"'ve" = " have",
"'ll" = " will",
"'m" = " am",
"'re" = " are",
"this's" = "this is",
"that's" = "that is",
"it's" = "it is",
"'s" = "",
"mr." = "",
"mrs." = "",
"ms." = "",
"sr." = ""
)
speech_df <- speech_df %>%
mutate(text = str_replace_all(string = text, pattern = patterns ) ) %>%
mutate(text = str_replace_all(text, pattern = "[^a-zA-Z\\s]", replacement = " ") )
words_df <- speech_df %>% unnest_tokens(word, text)
data("stop_words")
words_df <- words_df %>% anti_join(stop_words)
term_df <- words_df %>% count(word, date)
head(term_df)
# couting tf-idf and term document matrix
term_doc <- words_df %>% group_by(date, word) %>% summarise(count = n())
rm(term_doc)
a <- speech_df %>% group_by(date, president, party) %>% summarise()
a
term_df <- words_df %>% count(word, date)  # create the term document dataframe
term_df <- term_df %>% bind_tf_idf(word, date, n)
rm(a)
term_df
tmp <- speech_df %>% group_by(date, president, party) %>% summarise()   # create a dataframe with speech date, president, party
term_df <- term_df %>% left_join(tmp, by = c("date" = "date"))
term_df
saveRDS(term_df, '../datasets/US-president-speech-termdoc.Rds')
hist(term_df$tf_idf)
term_df %>% dplyr::filter(tf_idf < 0.05) %>%
ggplot(aes(x = tf_idf)) + geom_histogram(binwidth = 1e-3)
term_df %>% dplyr::filter(tf_idf < 0.04) %>%
ggplot(aes(x = tf_idf)) + geom_histogram(fill = "brown")
term_df %>% dplyr::filter(tf_idf < 0.035) %>%
ggplot(aes(x = tf_idf)) + geom_histogram(fill = "brown", bins = 1e3)
term_df %>% dplyr::filter(tf_idf < 0.035) %>%
ggplot(aes(x = tf_idf)) + geom_histogram(fill = "brown", bins = 1e2)
term_df %>% dplyr::filter(tf_idf < 0.035) %>%
ggplot(aes(x = tf_idf)) + geom_histogram(fill = "brown", bins = 2e2)
term_df %>% dplyr::filter(tf_idf < 0.02) %>%
ggplot(aes(x = tf_idf)) + geom_histogram(fill = "brown", bins = 2e2)
term_df %>% dplyr::filter(tf_idf < 0.01) %>%
ggplot(aes(x = tf_idf)) + geom_histogram(fill = "brown", bins = 2e2)
rm(words_df)
rm(tmp)
rm(speech_list)
a = term_df %>% dplyr::filter(party %in% c("Republican", "Democratic"))
rm(a)
term_df <- term_df %>% dplyr::filter(party %in% c("Republican", "Democratic"))
speech_dates <- unique(term_doc$date)
speech_dates <- unique(term_df$date)
head(speech_dates)
length(speech_dates)
809 * 0.75
set.seed(2020)  # set a seed so that this is reproducible
trainIndex <- sample(speech_dates, size = 609)
set.seed(2020)  # set a seed so that this is reproducible
trainIndex <- sample(speech_dates, size = 609)
# create training set
traindata <- term_df %>% filter(date %in% trainIndex)
traindata %>% group_by(party) %>% summarise(n = length(unique(date)))
# create testing set
testdata <- term_df %>% filter(! (date %in% trainIndex))
testdata %>% group_by(party) %>% summarise(n = length(unique(date)))
?lda_tidiers
?MASS::lda
library(Matrix)
head(traindata)
term_doc <- traindata %>% cast_sparse(word, date, n)
rm(term_doc)
train_doc <- traindata %>% cast_sparse(word, date, n)
dim(train_doc)
MASS::lda(train_doc)
a = MASS::lda(train_doc, traindata$party)
a = MASS::lda(t(train_doc), traindata$party)
dim(t(train_doc))
length(traindata$party)
rownames(train_doc)
colnames(train_doc)
speech_df
tmp <- speech_df %>% group_by(date, president, party) %>% summarise()   # create a dataframe with speech date, president, party
tmp
party_names <- tmp$party
names(party_names) <- tmp$date
train_labels <- party_names[colnames(train_doc)]
fit.LDA <- MASS::lda(t(train_doc), train_labels)
train_doc <- traindata %>% cast_sparse(word, date, n)
dim(train_doc)
a <- prcomp(train_doc)
a$sdev
a$center
plot(1:609, cumsum(a$sdev), type = "l")
a$rotation
sum(a$sdev)
sum(a$sdev^2)
plot(1:609, cumsum(a$sdev^2)/sum(a$sdev^2), type = "l")
rm(a)
train_doc <- traindata %>% cast_sparse(date, word, n)
dim(train_doc)
term_df
?top_n
red_term_df <- term_df %>%
group_by(party, date, word) %>%
summarise(mean_tf_idf = mean(tf_idf)) %>%
group_by(party) %>%
top_n(n = 100, wt = desc(tf_idf)) %>% ungroup()
red_term_df <- term_df %>%
group_by(party, date, word) %>%
summarise(mean_tf_idf = mean(tf_idf)) %>%
group_by(party) %>%
top_n(n = 100, wt = desc(mean_tf_idf)) %>% ungroup()
red_term_df
unique(red_term_df$word)
View(red_term_df)
red_term_df <- term_df %>%
group_by(party, word) %>%
summarise(mean_tf_idf = mean(tf_idf)) %>%
group_by(party) %>%
top_n(n = 100, wt = desc(mean_tf_idf)) %>% ungroup()
unique(red_term_df)
unique(red_term_df$word)
View(red_term_df)
red_term_df <- term_df %>%
group_by(party, word) %>%
summarise(mean_tf_idf = mean(tf_idf)) %>%
group_by(party) %>%
arrange(desc(mean_tf_idf)) %>% top_n(100)
red_term_df
table(red_term_df$party)
train_red <- traindata %>%
group_by(party, word) %>%
summarise(mean_tf_idf = mean(tf_idf)) %>%
group_by(party) %>%
arrange(desc(mean_tf_idf)) %>% top_n(100)
rm(red_term_df)
train_red
# filter both the traindata and testdata to contain only required words
traindata <- traindata %>% filter(word %in% train_red$word)
testdata <- testdata %>% filter(word %in% train_red$word)
train_doc <- traindata %>% cast_sparse()
rm(train_doc)
traindata
train_doc <- traindata %>% cast_sparse(date, word, n)
train_doc
dim(train_doc)
unique(traindata$president)
train_doc <- traindata %>% cast_sparse(date, word, n)
dim(train_doc)
test_doc <- testdata %>% cast_sparse(date, word, n)
dim(test_doc)
testdata
rownames(test_doc)
colnames(test_doc)
train_doc <- traindata %>% cast_sparse(date, word, n)
dim(train_doc)
set.seed(2020)  # set a seed so that this is reproducible
trainIndex <- sample(speech_dates, size = 609)
# create training set
traindata <- term_df %>% filter(date %in% trainIndex)
traindata %>% group_by(party) %>% summarise(n = length(unique(date)))
# create testing set
testdata <- term_df %>% filter(! (date %in% trainIndex))
testdata %>% group_by(party) %>% summarise(n = length(unique(date)))
# filter both the traindata and testdata to contain only required words
red_traindata <- traindata %>% filter(word %in% train_red$word)
red_testdata <- testdata %>% filter(word %in% train_red$word)
train_doc <- red_traindata %>% cast_sparse(date, word, n)
dim(train_doc)
unique(train_red$word)
length(unique(train_red$word))
red_traindata
red_words <- sort(unique(train_red$word))
red_traindata <- rbind(red_traindata, tibble(word = red_words, date = NA, n = 0, tf = 0, idf = 0, tf_idf = 0, president = NA, party = NA) )
tail(red_traindata)
train_doc <- red_traindata %>% cast_sparse(date, word, n)
dim(train_doc)
rownames(train_doc)
train_doc <- train_doc[!is.na(rownames(train_doc)), red_words]
dim(train_doc)
red_testdata <- rbind(red_testdata, tibble(word = red_words, date = NA, n = 0, tf = 0, idf = 0, tf_idf = 0, president = NA, party = NA) )
test_doc <- red_testdata %>% cast_sparse(date, word, n)
dim(test_doc)
test_doc <- red_testdata %>% cast_sparse(date, word, n)
test_doc <- train_doc[!is.na(rownames(test_doc)), red_words]
colnames(test_doc)
training_labels <- party_names[rownames(train_doc)]
testing_labels <- party_names[rownames(test_doc)]
testing_labels
fit.LDA <- MASS::lda(train_doc, training_labels)
fit.LDA
preds <- predict(fit.LDA, newdata = test_doc)
preds$class
preds$posterior
table(testing_labels, preds)
length(preds)
table(testing_labels, preds$class)
a, b, c <- c(1, 2, 3)
c(a, b, c) <- c(1, 2, 3)
setwd("D:/Dataprojects/Natural_Language_Processing_Soumendu_da/Text Mining in R")
term_df <- readRDS('../datasets/US-president-speech-termdoc.Rds')
term_df
unique(term_df$president)
term_df <- term_df %>% dplyr::filter(party %in% c("Republican", "Democratic"))
library(stringr)
library(tidytext)
library(dplyr)
library(ggplot2)
term_df <- term_df %>% dplyr::filter(party %in% c("Republican", "Democratic"))
speech_dates <- unique(term_df$date)
length(speech_dates)
set.seed(2020)  # set a seed so that this is reproducible
trainIndex <- sample(speech_dates, size = 609)
# create training set
traindata <- term_df %>% filter(date %in% trainIndex)
traindata %>% group_by(party) %>% summarise(n = length(unique(date)))
# create testing set
testdata <- term_df %>% filter(! (date %in% trainIndex))
testdata %>% group_by(party) %>% summarise(n = length(unique(date)))
party_names <- tmp$party
names(party_names) <- tmp$date
speeches <- list.files('../datasets/presidential-speeches/')
head(speeches)
tmp <- read_lines('../datasets/presidential-speeches/1789-04-30-first-inaugural-address.txt')
tmp[1:5]
library(readr)
tmp <- read_lines('../datasets/presidential-speeches/1789-04-30-first-inaugural-address.txt')
tmp[1:5]
speech_dates <- as.Date(substr(speeches, 1, 10))
speech_list <- vector(mode = "list", length = length(speeches))  # create a blank list
for (i in 1:length(speeches)) {
tmp <- read_lines(paste0('../datasets/presidential-speeches/', speeches[i]))
speech_list[[i]] <- tibble(line = 2:length(tmp), text = tmp[2:length(tmp)])  # we do not take the first line
speech_list[[i]]$president <- substring(tmp[1], 12)   # Take it from 12 character onwards
speech_list[[i]]$date <- speech_dates[i]
}
speech_df <- bind_rows(speech_list)  # finally bind all rows of
pres_df <- readRDS('../datasets/US-president.Rds')
pres_df
speech_df <- speech_df %>% filter(text != "") %>%
left_join(pres_df[, c(2, 3)], by = c("president" = "president"))
speech_df <- speech_df %>% mutate(text = str_to_lower(text) )
# the next thing is processing apostrophe
patterns <- c(
"n't" = " not",
"'ve" = " have",
"'ll" = " will",
"'m" = " am",
"'re" = " are",
"this's" = "this is",
"that's" = "that is",
"it's" = "it is",
"'s" = "",
"mr." = "",
"mrs." = "",
"ms." = "",
"sr." = ""
)
speech_df <- speech_df %>%
mutate(text = str_replace_all(string = text, pattern = patterns ) ) %>%
mutate(text = str_replace_all(text, pattern = "[^a-zA-Z\\s]", replacement = " ") )
words_df <- speech_df %>% unnest_tokens(word, text)
rm(words_df)
tmp <- speech_df %>% group_by(date, president, party) %>% summarise()   # create a dataframe with speech date, president, party
party_names <- tmp$party
names(party_names) <- tmp$date
train_red <- traindata %>%
group_by(party, word) %>%
summarise(mean_tf_idf = mean(tf_idf)) %>%
group_by(party) %>%
arrange(desc(mean_tf_idf)) %>% top_n(100)    # compute the top 100 words having highest mean_tf_idf
rm(speech_list)
# filter both the traindata and testdata to contain only required words
red_traindata <- traindata %>% filter(word %in% train_red$word)
red_testdata <- testdata %>% filter(word %in% train_red$word)
length(unique(train_red$word))
red_words <- sort(unique(train_red$word))
red_traindata <- rbind(red_traindata, tibble(word = red_words, date = NA, n = 0, tf = 0, idf = 0, tf_idf = 0, president = NA, party = NA) )
train_doc <- red_traindata %>% cast_sparse(date, word, n)
train_doc <- train_doc[!is.na(rownames(train_doc)), red_words]
dim(train_doc)
red_testdata <- rbind(red_testdata, tibble(word = red_words, date = NA, n = 0, tf = 0, idf = 0, tf_idf = 0, president = NA, party = NA) )
test_doc <- red_testdata %>% cast_sparse(date, word, n)
test_doc <- train_doc[!is.na(rownames(test_doc)), red_words]
dim(test_doc)
set.seed(2020)  # set a seed so that this is reproducible
trainIndex <- sample(speech_dates, size = 609)
# create training set
traindata <- term_df %>% filter(date %in% trainIndex)
traindata %>% group_by(party) %>% summarise(n = length(unique(date)))
# create testing set
testdata <- term_df %>% filter(! (date %in% trainIndex))
testdata %>% group_by(party) %>% summarise(n = length(unique(date)))
speech_dates
speech_dates <- unique(term_df$date)
length(speech_dates)
set.seed(2020)  # set a seed so that this is reproducible
trainIndex <- sample(speech_dates, size = 609)
# create training set
traindata <- term_df %>% filter(date %in% trainIndex)
traindata %>% group_by(party) %>% summarise(n = length(unique(date)))
# create testing set
testdata <- term_df %>% filter(! (date %in% trainIndex))
testdata %>% group_by(party) %>% summarise(n = length(unique(date)))
party_names <- tmp$party
names(party_names) <- tmp$date
library(Matrix)
train_doc <- traindata %>% cast_sparse(date, word, n)
dim(train_doc)
train_red <- traindata %>%
group_by(party, word) %>%
summarise(mean_tf_idf = mean(tf_idf)) %>%
group_by(party) %>%
arrange(desc(mean_tf_idf)) %>% top_n(100)    # compute the top 100 words having highest mean_tf_idf
# filter both the traindata and testdata to contain only required words
red_traindata <- traindata %>% filter(word %in% train_red$word)
red_testdata <- testdata %>% filter(word %in% train_red$word)
length(unique(train_red$word))
red_words <- sort(unique(train_red$word))
red_traindata <- rbind(red_traindata, tibble(word = red_words, date = NA, n = 0, tf = 0, idf = 0, tf_idf = 0, president = NA, party = NA) )
train_doc <- red_traindata %>% cast_sparse(date, word, n)
train_doc <- train_doc[!is.na(rownames(train_doc)), red_words]
dim(train_doc)
red_testdata <- rbind(red_testdata, tibble(word = red_words, date = NA, n = 0, tf = 0, idf = 0, tf_idf = 0, president = NA, party = NA) )
test_doc <- red_testdata %>% cast_sparse(date, word, n)
test_doc <- train_doc[!is.na(rownames(test_doc)), red_words]
dim(test_doc)
red_testdata
length(red_testdata$date)
length(unique(red_testdata$date))
test_doc <- red_testdata %>% cast_sparse(date, word, n)
test_doc <- test_doc[!is.na(rownames(test_doc)), red_words]
dim(test_doc)
training_labels <- party_names[rownames(train_doc)]
testing_labels <- party_names[rownames(test_doc)]
save(train_doc, test_doc, training_labels, testing_labels, file = "../datasets/US_president_ML_parts/ML_tfidf_top100.Rdata")
memory.profile()
object.size()
gc()
memory.size()
classification <- function(x,y){
# Making a function for the classification characteristics for a problem with levels 1 and 0.
# Here x and y are two vectors. x is the actual value while y is the vector of predicted values.
class_table = table(y , x)
print("Classification Matrix is (Row = Predicted, Column = Actual):")
print(class_table)
TP <- class_table[1, 1]; FP <- class_table[1, 2]; FN <- class_table[2, 1]; TN <- class_table[2, 2];
Accuracy = (TP+TN)/sum(class_table)
print(paste("Accuracy :", Accuracy))
print(paste("Classification error :", 1 - Accuracy))
preci = c(TP / (TP + FP), TN / (TN+FN) )
recall = c( TP / (TP + FN), TN / (TN + FP) )
F1 = 2 *(preci*recall)/(preci+recall)
class_df <- data.frame(Class = rownames(class_table), Precision = preci, Recall = recall, F1.measure = F1)
print("Classification Report :")
print(class_df)
Pe = (TP+FP)*(TP+FN)/(sum(class_table)^2) + (TN+FP)*(TN+FN)/(sum(class_table)^2)
print(paste("Cohen's Kappa:", (Accuracy - Pe)/(1 - Pe) ))
}
memory.size()
fit.LDA <- MASS::lda(train_doc, training_labels)
preds <- predict(fit.LDA, newdata = test_doc)
rm(classification)
classification_report <- function(x,y){
# Making a function for the classification characteristics for a problem with levels 1 and 0.
# Here x and y are two vectors. x is the actual value while y is the vector of predicted values.
class_table = table(y , x)
print("Classification Matrix is (Row = Predicted, Column = Actual):")
print(class_table)
TP <- class_table[1, 1]; FP <- class_table[1, 2]; FN <- class_table[2, 1]; TN <- class_table[2, 2];
Accuracy = (TP+TN)/sum(class_table)
print(paste("Accuracy :", Accuracy))
print(paste("Classification error :", 1 - Accuracy))
preci = c(TP / (TP + FP), TN / (TN+FN) )
recall = c( TP / (TP + FN), TN / (TN + FP) )
F1 = 2 *(preci*recall)/(preci+recall)
class_df <- data.frame(Class = rownames(class_table), Precision = preci, Recall = recall, F1.measure = F1)
print("Classification Report :")
print(class_df)
Pe = (TP+FP)*(TP+FN)/(sum(class_table)^2) + (TN+FP)*(TN+FN)/(sum(class_table)^2)
print(paste("Cohen's Kappa:", (Accuracy - Pe)/(1 - Pe) ))
}
classification_report(testing_labels, preds$class)
cat("Hello")
?cat
classification_report <- function(True_labels, Predicted_labels){
# Making a function for the classification characteristics for a problem with levels 1 and 0.
# Here x and y are two vectors. x is the actual value while y is the vector of predicted values.
class_table = table(Predicted_labels , True_labels)
cat("Classification Matrix is (Row = Predicted, Column = Actual):")
cat(class_table)
TP <- class_table[1, 1]; FP <- class_table[1, 2]; FN <- class_table[2, 1]; TN <- class_table[2, 2];
Accuracy = (TP+TN)/sum(class_table)
cat("Accuracy : ", Accuracy)
cat("Classification error : ", 1 - Accuracy)
preci = c(TP / (TP + FP), TN / (TN+FN) )
recall = c( TP / (TP + FN), TN / (TN + FP) )
F1 = 2 *(preci*recall)/(preci+recall)
class_df <- data.frame(Class = rownames(class_table), Precision = preci, Recall = recall, F1.measure = F1)
cat("Classification Report :")
cat(class_df)
Pe = (TP+FP)*(TP+FN)/(sum(class_table)^2) + (TN+FP)*(TN+FN)/(sum(class_table)^2)
cat("Cohen's Kappa: ", (Accuracy - Pe)/(1 - Pe) )
}
classification_report(testing_labels, preds$class)
classification_report <- function(True_labels, Predicted_labels){
# Making a function for the classification characteristics for a problem with levels 1 and 0.
# Here x and y are two vectors. x is the actual value while y is the vector of predicted values.
class_table = table(Predicted_labels , True_labels)
cat("Classification Matrix is (Row = Predicted, Column = Actual):\n")
print(class_table)
TP <- class_table[1, 1]; FP <- class_table[1, 2]; FN <- class_table[2, 1]; TN <- class_table[2, 2];
Accuracy = (TP+TN)/sum(class_table)
cat("Accuracy : ", Accuracy, "\n")
cat("Classification error : ", 1 - Accuracy, "\n")
preci = c(TP / (TP + FP), TN / (TN+FN) )
recall = c( TP / (TP + FN), TN / (TN + FP) )
F1 = 2 *(preci*recall)/(preci+recall)
class_df <- data.frame(Class = rownames(class_table), Precision = preci, Recall = recall, F1.measure = F1)
cat("Classification Report :\n")
print(class_df)
Pe = (TP+FP)*(TP+FN)/(sum(class_table)^2) + (TN+FP)*(TN+FN)/(sum(class_table)^2)
cat("Cohen's Kappa: ", (Accuracy - Pe)/(1 - Pe) )
}
classification_report(testing_labels, preds$class)
classification_report <- function(True_labels, Predicted_labels){
# Making a function for the classification characteristics for a problem with levels 1 and 0.
# Here x and y are two vectors. x is the actual value while y is the vector of predicted values.
class_table = table(Predicted_labels , True_labels)
cat("Classification Matrix is (Row = Predicted, Column = Actual):\n\n")
print(class_table)
TP <- class_table[1, 1]; FP <- class_table[1, 2]; FN <- class_table[2, 1]; TN <- class_table[2, 2];
Accuracy = (TP+TN)/sum(class_table)
cat("\n Accuracy : ", Accuracy, "\n")
cat("Classification error : ", 1 - Accuracy, "\n\n")
preci = c(TP / (TP + FP), TN / (TN+FN) )
recall = c( TP / (TP + FN), TN / (TN + FP) )
F1 = 2 *(preci*recall)/(preci+recall)
class_df <- data.frame(Class = rownames(class_table), Precision = preci, Recall = recall, F1.measure = F1)
cat("Classification Report :\n")
print(class_df)
Pe = (TP+FP)*(TP+FN)/(sum(class_table)^2) + (TN+FP)*(TN+FN)/(sum(class_table)^2)
cat("\n Cohen's Kappa: ", (Accuracy - Pe)/(1 - Pe) )
}
fit.LDA <- MASS::lda(train_doc, training_labels)
preds <- predict(fit.LDA, newdata = test_doc)
classification_report(testing_labels, preds$class)
dim(train_doc)
dim(test_doc)
fit.LDA <- MASS::lda(train_doc, training_labels)
preds <- predict(fit.LDA, newdata = test_doc)
classification_report(testing_labels, preds$class)
fit.QDA <- MASS::qda(train_doc, training_labels)
?MASS::qda()
a = as.matrix(train_doc)
dim(a)
a[1:10, 1:10]
object.size(a)
fit.QDA <- MASS::qda(a, training_labels)
training_labels
str(training_labels)
fit.QDA <- MASS::qda(train_doc, factor(training_labels))
str(factor(training_labels))
fit.LDA <- MASS::lda(train_doc, factor(training_labels))
preds <- predict(fit.LDA, newdata = test_doc)
classification_report(testing_labels, preds$class)
train_doc
dim(train_doc)
mu_repub <- colMeans(train_doc[training_labels == "Republican", ])
rm(fit.LDA)
mu_repub
var_repub <- var(train_doc[training_labels == "Republican", ])
a <- as.data.frame(train_doc)
a <- as.data.frame(as.matrix(train_doc))
head(a)
mu_repub <- colMeans(a[training_labels == "Republican", ])
var_repub <- var(a[training_labels == "Republican", ])
b <- solve(var_repub, mu_repub)
install.packages("e1071")
rm(a)
rm(mu_repub)
rm(var_repub)
library(e1071)
?naiveBayes
fit.NB <- naiveBayes(x = train_doc, y = factor(training_labels))
fit.NB <- naiveBayes(x = as.matrix(train_doc), y = factor(training_labels))
preds <- predict(fit.NB, newdata = as.matrix(test_doc))
str(preds)
classification_report(testing_labels, preds)
?svm
fit.SVM.poly <- svm(x = as.matrix(train_doc), y = factor(training_labels), kernel = "polynomial")
preds <- predict(fit.SVM.poly, newdata = as.matrix(test_doc))
classification_report(testing_labels, preds)
fit.SVM.radial <- svm(x = as.matrix(train_doc), y = factor(training_labels), kernel = "radial")
preds <- predict(fit.SVM.radial, newdata = as.matrix(test_doc))
classification_report(testing_labels, preds)
fit.SVM.sigmoid <- svm(x = as.matrix(train_doc), y = factor(training_labels), kernel = "sigmoid")
preds <- predict(fit.SVM.sigmoid, newdata = as.matrix(test_doc))
classification_report(testing_labels, preds)
?`e1071
``
`
